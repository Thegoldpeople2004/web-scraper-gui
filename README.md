以上是一个具体例子的网页信息爬取例子，
但对于每一个不同的网站，都需要进行一定的定制化开发，
分析该网站的HTML源码，找出其中存储有用信息的HTML元素的结构，然后根据这个结构调整爬虫程序代码。
这是因为不同网站间HTML结构的差异性，使得爬虫代码并不能一概而论，通用于所有网站。
以下是一个通用的爬取框架：

通过提供输入框让用户自定义选择器，使得对于没有硬编码在脚本中的网站也能尝试去爬取信息。
用户需要根据目标网站的具体HTML结构，输入合适的CSS选择器。
因此，用户需要具备一定的HTML/CSS知识，能够从浏览器的开发者工具中查找元素并编写CSS选择器。
这样的设计虽然提供了更大的灵活性，但是也增加了使用门槛。
对于不同的网站，用户需要根据具体情况调整selectors中的配置。
